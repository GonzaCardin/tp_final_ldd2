{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67379ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuración inicial\n",
    "warnings.filterwarnings('ignore')\n",
    "processed_data_path = '../data/processed/dataset_final.csv'\n",
    "\n",
    "try:\n",
    "    df_final = pd.read_csv(processed_data_path, index_col=0, parse_dates=True)\n",
    "    print('Se cargó el dataset procesado correctamente.')\n",
    "    print(f'Dimensiones del dataset: {df_final.shape}')\n",
    "except FileNotFoundError:\n",
    "    print(f'No se encontró el archivo en la ruta: {processed_data_path}')\n",
    "    df_final = pd.DataFrame()  \n",
    "\n",
    "if not df_final.empty:\n",
    "    # acá reconstruimos los sets de entrenamiento y prueba\n",
    "    \n",
    "    target_col = 'target' # la cambiamos de nombre en el preprocesamiento\n",
    "    X = df_final.drop(columns=[target_col])\n",
    "    y = df_final[target_col]\n",
    "    \n",
    "    train_size = int(len(X) * 0.70)\n",
    "    \n",
    "    X_train = X.iloc[:train_size]\n",
    "    X_test = X.iloc[train_size:]\n",
    "    y_train = y.iloc[:train_size]\n",
    "    y_test = y.iloc[train_size:]\n",
    "    \n",
    "    print('Sets de entrenamiento y prueba reconstruidos:')\n",
    "    print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "    print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')\n",
    "    \n",
    "    # confiugramos el tracking de experimentos\n",
    "    log_path = '../results/experiment_logs.csv'\n",
    "    os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(log_path):\n",
    "        header = [\n",
    "            'timestamp',\n",
    "            'model_name',\n",
    "            'model_version',\n",
    "            'mae',\n",
    "            'rmse',\n",
    "            'r2',\n",
    "            'parameters'\n",
    "        ]\n",
    "        pd.DataFrame(columns=header).to_csv(log_path, index=False)\n",
    "        print(f'Se creó el archivo de logs en: {log_path}')\n",
    "    else:\n",
    "        print(f'El archivo de logs ya existe en: {log_path}')\n",
    "else:\n",
    "    print('El dataset procesado está vacío. No se pueden reconstruir los sets de entrenamiento y prueba.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265286aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para evaluar modelos\n",
    "log_path = '../results/experiment_logs.csv'\n",
    "\n",
    "def train_and_log_model(model, model_name, params_dict, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Entrena el modelo, evalúa su desempeño \n",
    "    y registra los resultados en un archivo CSV.\n",
    "    \"\"\"\n",
    "    try:  \n",
    "        # entrenar el modelo\n",
    "        model.set_params(**params_dict)\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        # hacer predicciones\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "        # calcular métricas\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # para la versión del modelo\n",
    "        param_str = \"_\".join([f\"{k}_{v}\" for k, v in params_dict.items()])\n",
    "        model_version = f\"{model_name}_{param_str}\"\n",
    "    \n",
    "        # registrar los resultados\n",
    "        log_entry = {\n",
    "            'timestamp': pd.Timestamp.now(),\n",
    "            'model_name': model_name,\n",
    "            'model_version': model_version,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'parameters': str(params_dict)\n",
    "        }\n",
    "    \n",
    "        # guardar en CSV\n",
    "        log_df = pd.read_csv(log_path)\n",
    "        log_df = pd.concat([log_df, pd.DataFrame([log_entry])], ignore_index=True)\n",
    "        log_df.to_csv(log_path, index=False)\n",
    "        \n",
    "        print(f'Log guardado para el modelo {model_name} versión {version}.')\n",
    "        return model, mae\n",
    "    except Exception as e:\n",
    "        print(f'Error al entrenar y registrar el modelo: {e}')\n",
    "    return None, np.inf   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c643f",
   "metadata": {},
   "source": [
    "### Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f53f8e",
   "metadata": {},
   "source": [
    "#### Ridge/Lasso Regression (Lineales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train' in locals() and not X_train.empty:\n",
    "    # definimos el parámetro de busqueda para Ridge and Lasso\n",
    "    params_grid ={\n",
    "        'alpha':[0.01, 0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "    }\n",
    "    \n",
    "    # Ridge Regression\n",
    "    ridge_model = Ridge(random_state=42)\n",
    "    for alpha in params_grid['alpha']:\n",
    "        params = {'alpha': alpha}\n",
    "        train_and_log_model(\n",
    "            model=ridge_model,\n",
    "            model_name='Ridge_Regression',\n",
    "            params_dict=params,\n",
    "            X_train=X_train,y_train=y_train,\n",
    "            X_test=X_test,y_test=y_test\n",
    "        )\n",
    "    \n",
    "    # Lasso Regression\n",
    "    lasso_model = Lasso(random_state=42, max_iter=10000)\n",
    "    for alpha in params_grid['alpha']:\n",
    "        params = {'alpha': alpha}\n",
    "        train_and_log_model(\n",
    "            model=lasso_model,\n",
    "            model_name='Lasso_Regression',\n",
    "            params_dict=params,\n",
    "            X_train=X_train,y_train=y_train,\n",
    "            X_test=X_test,y_test=y_test\n",
    "        )\n",
    "    print('Entrenamientocompletado.')\n",
    "else:\n",
    "    print('No se pueden entrenar modelos porque los sets de entrenamiento están vacíos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14748c3",
   "metadata": {},
   "source": [
    "### Random Forest Regression, XGBoost (XGB Regression) y LightGBM (LGBM Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a2518",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train' in locals() and not X_train.empty:\n",
    "    # parámetros de búsqueda para los modelos\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    }\n",
    "    \n",
    "    # Random Forest Regression\n",
    "    rf_model = RandomForestRegressor(random_state=42,n_jobs=-1)\n",
    "    for n in param_grid['n_estimators']:\n",
    "        params = {'n_estimators': n}\n",
    "        train_and_log_model(\n",
    "            model=rf_model,\n",
    "            model_name='Random_Forest_Regression',\n",
    "            params_dict=params,\n",
    "            X_train=X_train,y_train=y_train,\n",
    "            X_test=X_test,y_test=y_test\n",
    "        )\n",
    "    \n",
    "    # XGBoost Regression\n",
    "    xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1)\n",
    "    for n in param_grid['n_estimators']:\n",
    "        params = {'n_estimators': n}\n",
    "        train_and_log_model(\n",
    "            model=xgb_model,\n",
    "            model_name='XGB_Regression',\n",
    "            params_dict=params,\n",
    "            X_train=X_train,y_train=y_train,\n",
    "            X_test=X_test,y_test=y_test\n",
    "        )\n",
    "    \n",
    "    # LightGBM Regression\n",
    "    lgbm_model = LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)\n",
    "    for n in param_grid['n_estimators']:\n",
    "        params = {'n_estimators': n}\n",
    "        train_and_log_model(\n",
    "            model=lgbm_model,\n",
    "            model_name='LGBM_Regression',\n",
    "            params_dict=params,\n",
    "            X_train=X_train,y_train=y_train,\n",
    "            X_test=X_test,y_test=y_test\n",
    "        )\n",
    "    print(f'Entrenamiento de modelos completados. Los resultados están registrados en el archivo de logs en: {log_path}')\n",
    "else:\n",
    "    print('No se pueden entrenar modelos porque los sets de entrenamiento están vacíos.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cervecera_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

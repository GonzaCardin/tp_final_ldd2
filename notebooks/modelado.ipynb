{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67379ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuración inicial\n",
    "warnings.filterwarnings('ignore')\n",
    "processed_data_path = '../data/processed/dataset_final.csv'\n",
    "\n",
    "try:\n",
    "    df_final = pd.read_csv(processed_data_path, index_col=0, parse_dates=True)\n",
    "    print('Se cargó el dataset procesado correctamente.')\n",
    "    print(f'Dimensiones del dataset: {df_final.shape}')\n",
    "except FileNotFoundError:\n",
    "    print(f'No se encontró el archivo en la ruta: {processed_data_path}')\n",
    "    df_final = pd.DataFrame()  \n",
    "\n",
    "if not df_final.empty:\n",
    "    # acá reconstruimos los sets de entrenamiento y prueba\n",
    "    \n",
    "    target_col = 'target' # la cambiamos de nombre en el preprocesamiento\n",
    "    X = df_final.drop(columns=[target_col])\n",
    "    y = df_final[target_col]\n",
    "    \n",
    "    train_size = int(len(X) * 0.70)\n",
    "    \n",
    "    X_train = X.iloc[:train_size]\n",
    "    X_test = X.iloc[train_size:]\n",
    "    y_train = y.iloc[:train_size]\n",
    "    y_test = y.iloc[train_size:]\n",
    "    \n",
    "    print('Sets de entrenamiento y prueba reconstruidos:')\n",
    "    print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "    print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')\n",
    "    \n",
    "    # confiugramos el tracking de experimentos\n",
    "    log_path = '../results/experiment_logs.csv'\n",
    "    os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(log_path):\n",
    "        header = [\n",
    "            'timestamp',\n",
    "            'model_name',\n",
    "            'model_version',\n",
    "            'mae',\n",
    "            'rmse',\n",
    "            'r2',\n",
    "            'parameters'\n",
    "        ]\n",
    "        pd.DataFrame(columns=header).to_csv(log_path, index=False)\n",
    "        print(f'Se creó el archivo de logs en: {log_path}')\n",
    "    else:\n",
    "        print(f'El archivo de logs ya existe en: {log_path}')\n",
    "else:\n",
    "    print('El dataset procesado está vacío. No se pueden reconstruir los sets de entrenamiento y prueba.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8eb823",
   "metadata": {},
   "source": [
    "Cargamos el dataset_final.csv procesado en la Fase 2. Luego, reconstruímos la división temporal 70/30 (usando .iloc[]) para tener disponibles las variables X_train, X_test, y_train, y y_test para el análisis, garantizando una validación temporal coherente.\n",
    "\n",
    "Por último, preparamos el seguimiento de experimentos al crear el archivo results/experiment_logs.csv (si no existe) con las cabeceras correctas, dejándolo listo para registrar los resultados de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265286aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para evaluar modelos\n",
    "log_path = '../results/experiment_logs.csv'\n",
    "\n",
    "def train_and_log_model(model, model_name, params_dict, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Entrena el modelo, evalúa su desempeño \n",
    "    y registra los resultados en un archivo CSV.\n",
    "    \"\"\"\n",
    "    try:  \n",
    "        # entrenar el modelo\n",
    "        model.set_params(**params_dict)\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        # hacer predicciones\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "        # calcular métricas\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # para la versión del modelo\n",
    "        param_str = \"_\".join([f\"{k}_{v}\" for k, v in params_dict.items()])\n",
    "        model_version_exp = f\"{model_name}_{param_str}\"\n",
    "    \n",
    "        # registrar los resultados\n",
    "        log_entry = {\n",
    "            'timestamp': pd.Timestamp.now(),\n",
    "            'model_name': model_name,\n",
    "            'model_version': model_version_exp,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'parameters': str(params_dict)\n",
    "        }\n",
    "    \n",
    "        # guardar en CSV\n",
    "        log_df = pd.read_csv(log_path)\n",
    "        log_df = pd.concat([log_df, pd.DataFrame([log_entry])], ignore_index=True)\n",
    "        log_df.to_csv(log_path, index=False)\n",
    "\n",
    "        print(f'Log guardado para el modelo {model_name} versión {model_version_exp}.')\n",
    "        return model, mae\n",
    "    except Exception as e:\n",
    "        print(f'Error al entrenar y registrar el modelo: {e}')\n",
    "    return None, np.inf   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a994561",
   "metadata": {},
   "source": [
    "Esta función, train_and_log_model, automatiza el Tracking de Experimentos.\n",
    "\n",
    "Su trabajo es: entrenar un modelo con un conjunto de hiperparámetros, evaluar el modelo calculando las métricas MAE, RMSE y R² sobre los datos de test;registrar (loggear) los resultados (métricas, parámetros y timestamp) como una nueva fila en el archivo experiment_logs.csv y, garantiza la trazabilidad y reproducibilidad de cada experimento, permitiendo comparar objetivamente los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c643f",
   "metadata": {},
   "source": [
    "### Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f53f8e",
   "metadata": {},
   "source": [
    "#### Ridge/Lasso Regression (Lineales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train' in locals() and not X_train.empty:\n",
    "    # definimos el parámetro de busqueda para Ridge and Lasso\n",
    "    params_grid ={\n",
    "        'alpha':[0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0]\n",
    "    }\n",
    "    \n",
    "    # Ridge Regression\n",
    "    ridge_model = Ridge(random_state=42)\n",
    "    for alpha in params_grid['alpha']:\n",
    "        params = {'alpha': alpha}\n",
    "        train_and_log_model(\n",
    "            model=ridge_model,\n",
    "            model_name='Ridge_Regression',\n",
    "            params_dict=params,\n",
    "            X_train=X_train,y_train=y_train,\n",
    "            X_test=X_test,y_test=y_test\n",
    "        )\n",
    "    \n",
    "    # Lasso Regression\n",
    "    lasso_model = Lasso(random_state=42, max_iter=10000)\n",
    "    for alpha in params_grid['alpha']:\n",
    "        params = {'alpha': alpha}\n",
    "        train_and_log_model(\n",
    "            model=lasso_model,\n",
    "            model_name='Lasso_Regression',\n",
    "            params_dict=params,\n",
    "            X_train=X_train,y_train=y_train,\n",
    "            X_test=X_test,y_test=y_test\n",
    "        )\n",
    "    print('Entrenamiento completado.')\n",
    "else:\n",
    "    print('No se pueden entrenar los modelos porque los sets de entrenamiento están vacíos.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f327b39",
   "metadata": {},
   "source": [
    "Realizamos una búsqueda de hiperparámetros manual (similar a Grid Search) para los modelos Ridge y Lasso. El objetivo es probar sistemáticamente qué valor de alpha da el mejor rendimiento (menor MAE) para los modelos Ridge y Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14748c3",
   "metadata": {},
   "source": [
    "### Random Forest Regression, XGBoost (XGB Regression) y LightGBM (LGBM Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a2518",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train' in locals() and not X_train.empty:\n",
    "    # parámetros de búsqueda para los modelos\n",
    "    param_grid = {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': [5, 10]\n",
    "    }\n",
    "    \n",
    "    # Random Forest Regression\n",
    "    rf_model = RandomForestRegressor(random_state=42,n_jobs=-1, verbose=0,min_samples_split=5)\n",
    "    for n in param_grid['n_estimators']:\n",
    "        params = {'n_estimators': n}\n",
    "        train_and_log_model(\n",
    "            model=rf_model,\n",
    "            model_name='Random_Forest_Regression',\n",
    "            params_dict=params,\n",
    "            X_train=X_train,y_train=y_train,\n",
    "            X_test=X_test,y_test=y_test\n",
    "        )\n",
    "    \n",
    "    # XGBoost Regression\n",
    "    xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1)\n",
    "    for n in param_grid['n_estimators']:\n",
    "        params = {'n_estimators': n}\n",
    "        train_and_log_model(\n",
    "            model=xgb_model,\n",
    "            model_name='XGB_Regression',\n",
    "            params_dict=params,\n",
    "            X_train=X_train,y_train=y_train,\n",
    "            X_test=X_test,y_test=y_test\n",
    "        )\n",
    "    \n",
    "    # LightGBM Regression\n",
    "    lgbm_model = LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)\n",
    "    for n in param_grid['n_estimators']:\n",
    "        params = {'n_estimators': n}\n",
    "        train_and_log_model(\n",
    "            model=lgbm_model,\n",
    "            model_name='LGBM_Regression',\n",
    "            params_dict=params,\n",
    "            X_train=X_train,y_train=y_train,\n",
    "            X_test=X_test,y_test=y_test\n",
    "        )\n",
    "    print(f'Entrenamiento de modelos completados. Los resultados están registrados en el archivo de logs en: {log_path}')\n",
    "else:\n",
    "    print('No se pueden entrenar modelos porque los sets de entrenamiento están vacíos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310af2df",
   "metadata": {},
   "source": [
    "Entrenamos los tres modelos avanzados basados en árboles (Random Forest, XGBoost, LightGBM), iterando sobre los hiperparámetros definidos en param_grid (en este caso, probando n_estimators=100).\n",
    "\n",
    "Es el núcleo del Tracking de Experimentos: llama a la función train_and_log_model para evaluar sistemáticamente cada modelo y registrar automáticamente sus métricas (MAE, RMSE, R²) y parámetros en el archivo experiment_logs.csv para su posterior análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b25e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_PATH = '../results/experiment_logs.csv' \n",
    "try:\n",
    "    logs_df = pd.read_csv(LOGS_PATH)\n",
    "    \n",
    "    logs_df_sorted = logs_df.sort_values(by='mae', ascending=True)\n",
    "    \n",
    "    print(\"\\nResultados de Experimentos (Ordenados por MAE):\")\n",
    "    display(logs_df_sorted)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"No se encontró el archivo de logs en {LOGS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097af94",
   "metadata": {},
   "source": [
    "Cargamos el archivo experiment_logs.csv, que contiene los resultados de todos los modelos entrenados. Luego, ordena los resultados por MAE (Mean Absolute Error) de menor a mayor. Esto se hace para identificar y seleccionar el mejor modelo basándose en la métrica de error principal, cumpliendo con el análisis del seguimiento de experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ed2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(x='mae', y='model_name', data=logs_df_sorted, palette='viridis')\n",
    "\n",
    "plt.title('Comparación de MAE de Validación entre Modelos', fontsize=16)\n",
    "plt.xlabel('Mean Absolute Error (MAE) - (Consumo Frio kW)', fontsize=12)\n",
    "plt.ylabel('Modelo', fontsize=12)\n",
    "\n",
    "\n",
    "plt.axvline(x=4000, color='red', linestyle='--', lw=2, label='Criterio Aprobación (MAE < 4000)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd43c0",
   "metadata": {},
   "source": [
    "Comparamos de rendimiento entre todos los modelos entrenados, un paso clave del Análisis de Modelos.\n",
    "\n",
    "Generamos un gráfico de barras (sns.barplot) que muestra el Error Absoluto Medio (MAE) de cada modelo en el set de validación, permitiendo una fácil comparación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cervecera_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
